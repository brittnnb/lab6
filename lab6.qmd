---
title: 'Lab 6: Machine Learning in Hydrology'
author: 'Brittany Bobb'
date: '2025-04-03'
format: 
    html:
      self-contained: true
execute:
  echo: true
editor: source
---

```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
library(dplyr)
library(readr)
library(purrr)
library(ggplot2)
library(patchwork)
library(ranger)
```

```{r}
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf')

```

```{r}
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
```

```{r}
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")
```

```{r}
# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
# where we want to download the data ...
local_files   <- glue('data/camels_{types}.txt')
```

```{r}
purrr::walk2(remote_files, local_files, download.file, quiet = TRUE)
```

```{r}
# Read and merge data
camels <-purrr::map(local_files, read_delim, show_col_types = FALSE) 
```

```{r}
camels <-powerjoin::power_full_join(camels ,by = 'gauge_id')
```

```{r}
#Question 1 ANSWER:According to the CAMELS dataset documentation, zero_q_freq represents the fraction of time during which streamflow is zero for a given basin or site. This is important for understanding the behavior of the streamflow over time and can be used to identify basins that experience dry conditions or intermittent flow.

```

```{r}
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "pink", high = "dodgerblue") +
  ggthemes::theme_map()
```

```{r}
# Question 2
```


```{r}
# Create map for aridity
map_aridity <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat, color = aridity)) +
  geom_point() +
  scale_color_viridis_c() + # Viridis scale for continuous data
  labs(title = "Aridity by Site", color = "Aridity") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  theme(axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank())

```

```{r}
# Create map for p_mean
map_pmean <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat, color = p_mean)) +
  geom_point() +
  scale_color_viridis_c() + # Viridis scale for continuous data
  labs(title = "Mean Precipitation by Site", color = "Mean Precipitation") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  theme(axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank())

```

```{r}
# Combine the two maps into one figure
combined_map <- map_aridity + map_pmean + plot_layout(ncol = 2)

# Display the combined maps
print(combined_map)

```

```{r}
# Reshape data to long format
camels_long <- camels %>%
  gather(key = "parameter", value = "value", aridity, p_mean)

# Create facet map
map_facet <- ggplot(camels_long, aes(x = gauge_lon, y = gauge_lat, color = value)) +
  geom_point() +
  scale_color_viridis_c() +
  labs(color = "Value") +
  facet_wrap(~parameter, scales = "free") + 
  theme_minimal() +
  theme(legend.position = "bottom")

# Display the facet map
print(map_facet)

```


```{r}
# Model Preparation 
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```

```{r}
# Visual EDA
# Create a scatter plot of aridity vs rainfall
ggplot(camels, aes(x = aridity, y = p_mean)) +
  # Add points colored by mean flow
  geom_point(aes(color = q_mean)) +
  # Add a linear regression line
  geom_smooth(method = "lm", color = "red", linetype = 2) +
  # Apply the viridis color scale
  scale_color_viridis_c() +
  # Add a title, axis labels, and theme (w/ legend on the bottom)
  theme_linedraw() + 
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
# Test a transformation 
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c() +
  # Apply log transformations to the x and y axes
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  # Apply a log transformation to the color scale
  scale_color_viridis_c(trans = "log") +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom",
        # Expand the legend width ...
        legend.key.width = unit(2.5, "cm"),
        legend.key.height = unit(.5, "cm")) + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow") 
```

```{r}
# Model Building 
# splitting the data 
set.seed(123)
# Bad form to perform simple transformations on the outcome variable within a 
# recipe. So, we'll do it here.
camels <- camels |> 
  mutate(logQmean = log(q_mean))

# Generate the split
camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

```{r}
# Create a recipe to preprocess the data
#logQmean ~ aridity + p_mean:
#This formula indicates that the target variable (logQmean) is being predicted using the predictor variables aridity and p_mean.logQmean: The dependent or outcome variable (the one you're trying to predict).aridity and p_mean: The independent or predictor variables (the ones you use to make predictions).

rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  # Log transform the predictor variables (aridity and p_mean)
  step_log(all_predictors()) %>%
  # Add an interaction term between aridity and p_mean
  step_interact(terms = ~ aridity:p_mean) |> 
  # Drop any rows with missing values in the pred
  step_naomit(all_predictors(), all_outcomes())
```

```{r}
# Naive base lm approach 
# Prepare the data
baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

# Interaction with lm
#  Base lm sets interaction terms with the * symbol
lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)
```

```{r}
# Sanity Interaction term from recipe ... these should be equal!!
summary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))
```

```{r}
# Where things get a little messy:
#The broom package provides a convenient way to extract model predictions and residuals. We can use the augment function to add predicted values to the test data. However, if we use augment directly on the test data, we will get incorrect results because the preprocessing steps defined in the recipe object have not been applied to the test data.
#Error in `$<-`:! Assigned data `predict(x, na.action = na.pass, ...) %>% unname()` must  be compatible with existing data.✖ Existing data has 135 rows.✖ Assigned data has 535 rows.ℹ Only vectors of size 1 are recycled.Caused by error in `vectbl_recycle_rhs_rows()`:! Can't recycle input of size 535 to size 135.

#The predict function can be used to make predictions on new data. However, if we use predict directly on the test data, we will get incorrect results because the preprocessing steps defined in the recipe object have not been applied to the test data.
```

```{r}
# Correct version: prep, bake, predict 
#To correctly evaluate the model on the test data, we need to apply the same preprocessing steps to the test data that we applied to the training data. We can do this using the prep and bake functions with the recipe object. This ensures the test data is transformed in the same way as the training data before making predictions.
```

```{r}
test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)
```

```{r}
# Model Evaluations : statistical vs visual
#Now that we have the predicted values, we can evaluate the model using the metrics function from the yardstick package. This function calculates common regression metrics such as RMSE, R-squared, and MAE between the observed and predicted values.
metrics(test_data, truth = logQmean, estimate = lm_pred)
```

```{r}
ggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +
  # Apply a gradient color scale
  scale_color_gradient2(low = "brown", mid = "orange", high = "darkgreen") +
  geom_point() +
  geom_abline(linetype = 2) +
  theme_linedraw() + 
  labs(title = "Linear Model: Observed vs Predicted",
       x = "Observed Log Mean Flow",
       y = "Predicted Log Mean Flow",
       color = "Aridity")
```

```{r}
# Ok so that was a bit burdensome, is really error prone (fragile), and is worthless if we wanted to test a different algorithm… lets look at a better approach!
```

```{r}
# Using a workflow instead 
# Define model
lm_model <- linear_reg() %>%
  # define the engine
  set_engine("lm") %>%
  # define the mode
  set_mode("regression")

# Instantiate a workflow ...
lm_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(lm_model) %>%
  # Fit the model to the training data
  fit(data = camels_train) 

# Extract the model coefficients from the workflow
summary(extract_fit_engine(lm_wf))$coefficients
```

```{r}
# From the base implementation
summary(lm_base)$coefficients
```

```{r}
# Making Predictions 
#Now that lm_wf is a workflow, data is not embedded in the model, we can use augment with the new_data argument to make predictions on the test data.

lm_data <- augment(lm_wf, new_data = camels_test)
dim(lm_data)
```

```{r}
# Model Evaluations: statistical and visual 

#As with EDA, applying for graphical and statistical evaluation of the model is a key Here, we use the metrics function to extract the default metrics (rmse, rsq, mae) between the observed and predicted mean streamflow values.

#We then create a scatter plot of the observed vs predicted values, colored by aridity, to visualize the model performance.

metrics(lm_data, truth = logQmean, estimate = .pred)
ggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

```{r}
# Switch it up: We define a random forest model using the rand_forest function, set the engine to ranger, and the mode to regression. We then add the recipe, fit the model, and evaluate the skill.

rf_model <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(rf_model) %>%
  # Fit the model
  fit(data = camels_train) 
```

```{r}
#Predictions 
#Make predictions on the test data using the augment function and the new_data argument.

rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)
```

```{r}
# Model Evaluation 
#Evaluate the model using the metrics function and create a scatter plot of the observed vs predicted values, colored by aridity.

metrics(rf_data, truth = logQmean, estimate = .pred)
```

```{r}
ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

```{r}
# A workflowset approach 
# workflow_set is a powerful tool for comparing multiple models on the same data. It allows you to define a set of workflows, fit them to the same data, and evaluate their performance using a common metric. Here, we are going to create a workflow_set object with the linear regression and random forest models, fit them to the training data, and compare their performance using the autoplot and rank_results functions.
```

